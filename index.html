<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Layer Analysis</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 0;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .chart-container {
            position: relative;
            height: 400px;
            margin-bottom: 40px;
        }
        .explanation {
            background-color: #f1f8ff;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
            border-left: 4px solid #4a7ebb;
        }
        .tabs {
            display: flex;
            margin-bottom: 20px;
        }
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            background-color: #eee;
            border: none;
            outline: none;
            border-radius: 5px 5px 0 0;
            margin-right: 2px;
        }
        .tab.active {
            background-color: #4a7ebb;
            color: white;
        }
        .tab-content {
            display: none;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 0 0 5px 5px;
        }
        .tab-content.active {
            display: block;
        }
        .highlight {
            background-color: #fffde7;
            padding: 2px 5px;
            border-radius: 3px;
        }
        .text-sample {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            white-space: pre-wrap;
            font-family: monospace;
            font-size: 14px;
            max-height: 200px;
            overflow-y: auto;
        }
        .correct {
            background-color: #e8f5e9;
            border-left: 4px solid #4caf50;
        }
        .incorrect {
            background-color: #ffebee;
            border-left: 4px solid #f44336;
        }
        .legend {
            display: flex;
            margin-bottom: 10px;
        }
        .legend-item {
            display: flex;
            align-items: center;
            margin-right: 20px;
        }
        .legend-color {
            width: 16px;
            height: 16px;
            border-radius: 3px;
            margin-right: 8px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Neural Network Layer Analysis</h1>
        
        <div class="explanation">
            <h3>About This Analysis</h3>
            <p>This visualization explores how information is processed through the layers of a neural network based on the provided example data. We examine two different approaches:</p>
            <ul>
                <li><strong>Progressive Inclusion</strong>: Starting with information from the initial layers and progressively adding information from subsequent layers.</li>
                <li><strong>Progressive Deduction</strong>: Starting with information from all layers and progressively removing information from deeper layers.</li>
            </ul>
            <p>The accuracy scores shown for each layer configuration indicate how well the network reconstructs the original input text.</p>
        </div>

        <div class="tabs">
            <button class="tab active" onclick="openTab(event, 'progressive-inclusion')">Progressive Inclusion</button>
            <button class="tab" onclick="openTab(event, 'progressive-deduction')">Progressive Deduction</button>
            <button class="tab" onclick="openTab(event, 'layer-ablation')">Layer Ablation</button>
            <button class="tab" onclick="openTab(event, 'comparison')">Comparison</button>
        </div>

        <div id="progressive-inclusion" class="tab-content active">
            <h2>Progressive Inclusion Analysis</h2>
            <p>This shows the accuracy as we progressively include information from more layers, starting from the earliest layers.</p>
            
            <div class="legend">
                <div class="legend-item">
                    <div class="legend-color" style="background-color: #4a7ebb;"></div>
                    <span>Accuracy</span>
                </div>
            </div>
            
            <div class="chart-container">
                <canvas id="progressiveInclusionChart"></canvas>
            </div>

            <h3>Text Samples Comparison</h3>
            <p>Comparing text reconstruction at different layer depths:</p>
            
            <h4>Low Accuracy Layer (up_to_layer_3, Accuracy: 0.23)</h4>
            <div class="text-sample incorrect">
annual of computer learning by long the we learn the questions for the development. Comput networks are when by the enormous intuition, fundamental, have of four individuals, in a that Each cluster has one internal neighborhood, is whether shape; Every each, the connections limit generated according the involvementagandament to guide algorith bias. The- in this architecture by highlighting eight neural neural to such the process for participate for formulas.
netsers testing networks can at observing- and manipulating this for reverse out critical of vis structural, During, the tasks networks ( much data, matching an associationized database, We that by to 1970, focusise the cognition processing. monitoring gibursion with gib. that consider the integrity of the broadcast's all particular better<|endoftext|> this made still to the in and deep learning biology computational manipulation, or general-,. the early, progress remain predominantly fashion where as taskability, paper study and and errorness. resultsarial analysis.
            </div>
            
            <h4>High Accuracy Layer (up_to_layer_10, Accuracy: 0.99)</h4>
            <div class="text-sample correct">
The development of machine learning has transformed how we approach complex problems in computer science. Neural networks, inspired by the human brain's architecture, consist of interconnected nodes organized in layers. Each connection has an associated weight that determines its importance. During training, these weights are adjusted through backpropagation to minimize prediction errors. Deep learning extends this concept by employing multiple hidden layers, enabling the network to learn hierarchical features. Convolutional neural networks excel at image processing by applying filters to detect patterns regardless of their location. Meanwhile, recurrent neural networks handle sequential data by maintaining an internal memory state. Transformers, introduced in 2017, revolutionized natural language processing by replacing recurrence with attention mechanisms that weigh the importance of each element in a sequence. This innovation has led to breakthroughs in machine translation, text generation, and question answering systems. Despite these advances, challenges remain in areas such as interpretability, data efficiency, and robustness to adversarial examples.
            </div>

            <h3>Key Insights:</h3>
            <ul>
                <li>Very low accuracy in early layers (up to layer 3) suggests these layers capture primarily low-level features</li>
                <li>A significant jump in accuracy occurs around layer 9-10, suggesting these are critical integration layers</li>
                <li>The text becomes coherent and meaningful only in the later layers (10+)</li>
                <li>Layers 0-8 produce text that has some topical relevance but lacks cohesive structure and clarity</li>
            </ul>
        </div>

        <div id="progressive-deduction" class="tab-content">
            <h2>Progressive Deduction Analysis</h2>
            <p>This shows the accuracy as we progressively remove information from deeper layers, starting with all layers.</p>
            
            <div class="legend">
                <div class="legend-item">
                    <div class="legend-color" style="background-color: #e57373;"></div>
                    <span>Accuracy</span>
                </div>
            </div>
            
            <div class="chart-container">
                <canvas id="progressiveDeductionChart"></canvas>
            </div>

            <h3>Text Samples Comparison</h3>
            <p>Comparing text reconstruction when starting from different layers:</p>
            
            <h4>Starting from layer 0 (Accuracy: 1.0)</h4>
            <div class="text-sample correct">
The development of machine learning has transformed how we approach complex problems in computer science. Neural networks, inspired by the human brain's architecture, consist of interconnected nodes organized in layers. Each connection has an associated weight that determines its importance. During training, these weights are adjusted through backpropagation to minimize prediction errors. Deep learning extends this concept by employing multiple hidden layers, enabling the network to learn hierarchical features. Convolutional neural networks excel at image processing by applying filters to detect patterns regardless of their position. Meanwhile, recurrent neural networks handle sequential data by maintaining an internal memory state. Transformers, introduced in 2017, revolutionized natural language processing by replacing recurrence with attention mechanisms that weigh the importance of each element in a sequence. This innovation has led to breakthroughs in machine translation, text generation, and question answering systems. Despite these advances, challenges remain in areas such as interpretability, data efficiency, and robustness to adversarial examples.
            </div>
            
            <h4>Starting from layer 5 (Accuracy: 0.49)</h4>
            <div class="text-sample incorrect">
But month struggle the learning through always this we govern complex languages in complex science. This networks shrink robotics by sensory evolution mind, acquisition, have of hundreds electrical that by tw below Each block has knowledge algorithm acronym. each that cod. Millions programs a a top move complex more back optimizationensityation, correctly load errors. G learning is range exciting by generating the functional arms for such the brain to navigate weaknesses connections and
olution of data networks do at the recognition ( avoiding groups to actively super short of the ecological. Despite, horizontal networks networks support the hundreds capture manipulating relatively observable structure stream in
 bes today as late during andise the computing science. employing naturalursion with open- by minim each mode of each image's a machine. Ge innovation showed extended to multiples by computing models advance which processing and and dominance answering.. This the advantages, applications in relatively the where as musicability. intelligence processing, and concrete coding emulation thearial intelligence.
            </div>

            <h3>Key Insights:</h3>
            <ul>
                <li>Starting from layer 0 (with all layers) gives perfect reconstruction</li>
                <li>Accuracy drops dramatically when starting from layer 1 (0.51) and continues to decline</li>
                <li>Even starting from the latest layer (layer 11), accuracy is very low (0.31), suggesting that text representation is distributed across all layers</li>
                <li>Each successive layer removes coherent structure from the text</li>
            </ul>
        </div>

        <div id="layer-ablation" class="tab-content">
            <h2>Layer Ablation Analysis</h2>
            <p>This shows the accuracy when each individual layer is used in isolation.</p>
            
            <div class="legend">
                <div class="legend-item">
                    <div class="legend-color" style="background-color: #81c784;"></div>
                    <span>Accuracy</span>
                </div>
            </div>
            
            <div class="chart-container">
                <canvas id="layerAblationChart"></canvas>
            </div>

            <h3>Text Samples Comparison</h3>
            <p>Comparing text reconstruction from individual layers:</p>
            
            <h4>Layer 2 (Accuracy: 0.41)</h4>
            <div class="text-sample incorrect">
But development of a learning revolution left our we work complex games in class-; Neural networks in inspired by a evolution brain's biology, have of rich electrical. as clusters along Each connection is an event program running determines its optimal to During manipulating a these weights are determined by actions learningagation. determine the of. Deep learning functions the concept with enabling multi functions techniques for enabling increasingly data to quantify perpendicular structures of Aolution drawing descent networks always atand stabilization by isol groups to detect how regardless of their relative. Meanwhile, EEG performance networks are the GPUs like simply compact even alignment stream.
, introduced in O, andized memory language completely in employing whiteurrence with ext.[ by imp rather mode of spatial element in a sequence. This creates is increased to fundamentals in conc learning. meaningful input, and gap of technologies. Despite currently advances, great still extremely areas that as intelligenceability, data flexibility, and human input to datasetsarial real.
            </div>
            
            <h4>Layer 10 (Accuracy: 1.0)</h4>
            <div class="text-sample correct">
The development of machine learning has transformed how we approach complex problems in computer science. Neural networks, inspired by the human brain's architecture, consist of interconnected nodes organized in layers. Each connection has an associated weight that determines its importance. During training, these weights are adjusted through backpropagation to minimize prediction errors. Deep learning extends this concept by employing multiple hidden layers, enabling the network to learn hierarchical features. Convolutional neural networks excel at image processing by applying filters to detect patterns regardless of their position. Meanwhile, recurrent neural networks handle sequential data by maintaining an internal memory state. Transformers, introduced in 2017, revolutionized natural language processing by replacing recurrence with attention mechanisms that weigh the importance of each element in a sequence. This innovation has led to breakthroughs in machine translation, text generation, and question answering systems. Despite these advances, challenges remain in areas such as interpretability, data efficiency, and robustness to adversarial examples.
            </div>

            <h3>Key Insights:</h3>
            <ul>
                <li>Layers 0-9 in isolation produce poor text reconstruction (accuracy < 0.71)</li>
                <li>Layers 10 and 11 each independently produce perfect text reconstruction (accuracy = 1.0)</li>
                <li>This suggests that the final layers contain a complete representation of the text</li>
                <li>Earlier layers seem to focus on specific aspects of text structure rather than complete meaning</li>
            </ul>
        </div>

        <div id="comparison" class="tab-content">
            <h2>Comparative Analysis</h2>
            <p>Comparing the three different approaches to layer analysis.</p>
            
            <div class="legend">
                <div class="legend-item">
                    <div class="legend-color" style="background-color: #4a7ebb;"></div>
                    <span>Progressive Inclusion</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background-color: #e57373;"></div>
                    <span>Progressive Deduction</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background-color: #81c784;"></div>
                    <span>Layer Ablation</span>
                </div>
            </div>
            
            <div class="chart-container">
                <canvas id="comparisonChart"></canvas>
            </div>

            <h3>Key Findings:</h3>
            <ul>
                <li>Progressive inclusion shows that accuracy increases as we add more layers, with a dramatic improvement in layers 9-10</li>
                <li>Progressive deduction shows that the model's ability to reconstruct text degrades quickly when we start excluding the earliest layers</li>
                <li>Layer ablation reveals that layers 10-11 individually contain the most complete representation of the text</li>
                <li>The patterns suggest that early layers (0-9) process features that are incrementally integrated, while the final layers (10-11) contain the complete text representation</li>
                <li>There appears to be a critical transition point around layer 9-10 where the neural network achieves near-perfect text reconstruction</li>
            </ul>

            <h3>Implications:</h3>
            <p>These findings demonstrate how neural network representations evolve through layers:</p>
            <ul>
                <li>Early layers capture simpler patterns and relationships</li>
                <li>Middle layers integrate these patterns into more complex structures</li>
                <li>Final layers contain the most coherent and complete representations</li>
                <li>The architecture shows a progression from low-level to high-level information processing</li>
            </ul>
        </div>
    </div>

    <script>
        // Data for progressive inclusion
        const progressiveInclusionData = [
            { layer: "up_to_layer_1", accuracy: 0.29100528359413147 },
            { layer: "up_to_layer_2", accuracy: 0.2857142686843872 },
            { layer: "up_to_layer_3", accuracy: 0.23280422389507294 },
            { layer: "up_to_layer_4", accuracy: 0.2539682388305664 },
            { layer: "up_to_layer_5", accuracy: 0.28042328357696533 },
            { layer: "up_to_layer_6", accuracy: 0.4126983880996704 },
            { layer: "up_to_layer_7", accuracy: 0.4444444179534912 },
            { layer: "up_to_layer_8", accuracy: 0.5238094925880432 },
            { layer: "up_to_layer_9", accuracy: 0.6719576716423035 },
            { layer: "up_to_layer_10", accuracy: 0.9947089552879333 },
            { layer: "up_to_layer_11", accuracy: 0.9999999403953552 },
            { layer: "up_to_layer_12", accuracy: 0.9999999403953552 }
        ];

        // Data for progressive deduction
        const progressiveDeductionData = [
            { layer: "from_layer_0", accuracy: 0.9999999403953552 },
            { layer: "from_layer_1", accuracy: 0.5132275223731995 },
            { layer: "from_layer_2", accuracy: 0.43915343284606934 },
            { layer: "from_layer_3", accuracy: 0.33862432837486267 },
            { layer: "from_layer_4", accuracy: 0.2857142686843872 },
            { layer: "from_layer_5", accuracy: 0.24867723882198334 },
            { layer: "from_layer_6", accuracy: 0.2222222089767456 },
            { layer: "from_layer_7", accuracy: 0.2857142686843872 },
            { layer: "from_layer_8", accuracy: 0.29100528359413147 },
            { layer: "from_layer_9", accuracy: 0.29629629850387573 },
            { layer: "from_layer_10", accuracy: 0.32275131344795227 },
            { layer: "from_layer_11", accuracy: 0.31216931343078613 }
        ];

        // Data for layer ablation
        const layerAblationData = [
            { layer: "layer_0", accuracy: 0.5132275223731995 },
            { layer: "layer_1", accuracy: 0.6931216716766357 },
            { layer: "layer_2", accuracy: 0.4126983880996704 },
            { layer: "layer_3", accuracy: 0.47089946269989014 },
            { layer: "layer_4", accuracy: 0.5449735522270203 },
            { layer: "layer_5", accuracy: 0.4920634627342224 },
            { layer: "layer_6", accuracy: 0.5873015522956848 },
            { layer: "layer_7", accuracy: 0.6296296119689941 },
            { layer: "layer_8", accuracy: 0.6613756418228149 },
            { layer: "layer_9", accuracy: 0.7037037014961243 },
            { layer: "layer_10", accuracy: 0.9999999403953552 },
            { layer: "layer_11", accuracy: 0.9999999403953552 }
        ];

        // Function to create charts
        function createCharts() {
            // Progressive Inclusion Chart
            const ctxPI = document.getElementById('progressiveInclusionChart').getContext('2d');
            new Chart(ctxPI, {
                type: 'line',
                data: {
                    labels: progressiveInclusionData.map(d => d.layer.replace('up_to_layer_', 'Layer ')),
                    datasets: [{
                        label: 'Accuracy',
                        data: progressiveInclusionData.map(d => d.accuracy),
                        backgroundColor: 'rgba(74, 126, 187, 0.2)',
                        borderColor: 'rgba(74, 126, 187, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: progressiveInclusionData.map(d => 
                            d.accuracy > 0.7 ? '#4caf50' : '#f44336'
                        ),
                        pointRadius: 5,
                        tension: 0.1
                    }]
                },
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 1,
                            title: {
                                display: true,
                                text: 'Accuracy'
                            }
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Layer Configuration'
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Progressive Inclusion Accuracy'
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `Accuracy: ${(context.raw * 100).toFixed(2)}%`;
                                }
                            }
                        }
                    }
                }
            });

            // Progressive Deduction Chart
            const ctxPD = document.getElementById('progressiveDeductionChart').getContext('2d');
            new Chart(ctxPD, {
                type: 'line',
                data: {
                    labels: progressiveDeductionData.map(d => d.layer.replace('from_layer_', 'Layer ')),
                    datasets: [{
                        label: 'Accuracy',
                        data: progressiveDeductionData.map(d => d.accuracy),
                        backgroundColor: 'rgba(229, 115, 115, 0.2)',
                        borderColor: 'rgba(229, 115, 115, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: progressiveDeductionData.map(d => 
                            d.accuracy > 0.7 ? '#4caf50' : '#f44336'
                        ),
                        pointRadius: 5,
                        tension: 0.1
                    }]
                },
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 1,
                            title: {
                                display: true,
                                text: 'Accuracy'
                            }
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Starting Layer'
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Progressive Deduction Accuracy'
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `Accuracy: ${(context.raw * 100).toFixed(2)}%`;
                                }
                            }
                        }
                    }
                }
            });

            // Layer Ablation Chart
            const ctxLA = document.getElementById('layerAblationChart').getContext('2d');
            new Chart(ctxLA, {
                type: 'line',
                data: {
                    labels: layerAblationData.map(d => d.layer.replace('layer_', 'Layer ')),
                    datasets: [{
                        label: 'Accuracy',
                        data: layerAblationData.map(d => d.accuracy),
                        backgroundColor: 'rgba(129, 199, 132, 0.2)',
                        borderColor: 'rgba(129, 199, 132, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: layerAblationData.map(d => 
                            d.accuracy > 0.7 ? '#4caf50' : '#f44336'
                        ),
                        pointRadius: 5,
                        tension: 0.1
                    }]
                },
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 1,
                            title: {
                                display: true,
                                text: 'Accuracy'
                            }
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Layer'
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Layer Ablation Accuracy'
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `Accuracy: ${(context.raw * 100).toFixed(2)}%`;
                                }
                            }
                        }
                    }
                }
            });

            // Comparison Chart
            const ctxComp = document.getElementById('comparisonChart').getContext('2d');
            new Chart(ctxComp, {
                type: 'line',
                data: {
                    labels: Array.from({ length: 12 }, (_, i) => `Layer ${i}`),
                    datasets: [
                        {
                            label: 'Progressive Inclusion',
                            data: progressiveInclusionData.map(d => d.accuracy),
                            backgroundColor: 'rgba(74, 126, 187, 0.2)',
                            borderColor: 'rgba(74, 126, 187, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        },
                        {
                            label: 'Progressive Deduction',
                            data: progressiveDeductionData.map(d => d.accuracy),
                            backgroundColor: 'rgba(229, 115, 115, 0.2)',
                            borderColor: 'rgba(229, 115, 115, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        },
                        {
                            label: 'Layer Ablation',
                            data: layerAblationData.map(d => d.accuracy),
                            backgroundColor: 'rgba(129, 199, 132, 0.2)',
                            borderColor: 'rgba(129, 199, 132, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        }
                    ]
                },
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 1,
                            title: {
                                display: true,
                                text: 'Accuracy'
                            }
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Layer'
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Comparison of Different Layer Analysis Approaches'
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `${context.dataset.label}: ${(context.raw * 100).toFixed(2)}%`;
                                }
                            }
                        }
                    }
                }
            });
        }

        // Function to handle tab switching
        function openTab(evt, tabName) {
            // Hide all tab content
            const tabContents = document.getElementsByClassName("tab-content");
            for (let i = 0; i < tabContents.length; i++) {
                tabContents[i].classList.remove("active");
            }

            // Remove active class from all tabs
            const tabs = document.getElementsByClassName("tab");
            for (let i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove("active");
            }

            // Show the selected tab content
            document.getElementById(tabName).classList.add("active");
            
            // Add active class to the clicked tab
            evt.currentTarget.classList.add("active");
        }

        // Initialize charts when page loads
        window.onload = createCharts;
    </script>
</body>
</html>
